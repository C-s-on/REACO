{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"OCmoCs3dLebJ","outputId":"06965005-5ccb-478e-d75b-fa718eba9982"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","0: 320x320 1 face, 282.1ms\n","Speed: 17.4ms preprocess, 282.1ms inference, 1153.4ms postprocess per image at shape (1, 3, 320, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\AARAV\\aarav 2.0_face_1.jpg\n","\n","0: 320x192 1 face, 152.4ms\n","Speed: 2.0ms preprocess, 152.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\AARAV\\IMG_3687_face_1.jpg\n","\n","0: 320x224 1 face, 205.6ms\n","Speed: 2.0ms preprocess, 205.6ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\AARAV\\_DSC0246_face_1.jpg\n","\n","0: 320x224 1 face, 173.3ms\n","Speed: 0.0ms preprocess, 173.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\AARAV\\_DSC0325_face_1.jpg\n","\n","0: 320x192 1 face, 145.0ms\n","Speed: 4.9ms preprocess, 145.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\ARYAN\\IMG_6035_face_1.jpg\n","\n","0: 320x192 1 face, 133.8ms\n","Speed: 0.0ms preprocess, 133.8ms inference, 15.1ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\ARYAN\\IMG_6036_face_1.jpg\n","\n","0: 224x320 1 face, 182.4ms\n","Speed: 0.0ms preprocess, 182.4ms inference, 10.3ms postprocess per image at shape (1, 3, 224, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\ASHIM\\_DSC0258_face_1.jpg\n","\n","0: 224x320 1 face, 158.0ms\n","Speed: 1.0ms preprocess, 158.0ms inference, 5.0ms postprocess per image at shape (1, 3, 224, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\ASHIM\\_DSC0259_face_1.jpg\n","\n","0: 320x224 1 face, 177.0ms\n","Speed: 0.7ms preprocess, 177.0ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\ASHIM\\_DSC0265_face_1.jpg\n","\n","0: 320x224 1 face, 152.0ms\n","Speed: 2.0ms preprocess, 152.0ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\ASHIM\\_MG_9959_face_1.jpg\n","\n","0: 320x192 1 face, 137.0ms\n","Speed: 1.0ms preprocess, 137.0ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\bhupi\\IMG_4397_face_1.jpg\n","\n","0: 320x192 1 face, 136.0ms\n","Speed: 1.0ms preprocess, 136.0ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\bhupi\\IMG_4398_face_1.jpg\n","\n","0: 224x320 2 faces, 153.7ms\n","Speed: 2.0ms preprocess, 153.7ms inference, 7.0ms postprocess per image at shape (1, 3, 224, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\bhupi\\_MG_9540_face_1.jpg\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\bhupi\\_MG_9540_face_2.jpg\n","\n","0: 288x320 3 faces, 229.4ms\n","Speed: 2.0ms preprocess, 229.4ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\bikash\\_DSC0077_face_1.jpg\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\bikash\\_DSC0077_face_2.jpg\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\bikash\\_DSC0077_face_3.jpg\n","\n","0: 320x256 1 face, 173.2ms\n","Speed: 2.0ms preprocess, 173.2ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 256)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\darwin\\_DSC0136_face_1.jpg\n","\n","0: 224x320 1 face, 152.9ms\n","Speed: 3.2ms preprocess, 152.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\dipak\\IMG_9677_face_1.jpg\n","\n","0: 320x192 1 face, 137.6ms\n","Speed: 7.0ms preprocess, 137.6ms inference, 16.1ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\DIWAS\\IMG_4433_face_1.jpg\n","\n","0: 320x224 1 face, 134.7ms\n","Speed: 1.6ms preprocess, 134.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\DIWAS\\_DSC0239_face_1.jpg\n","\n","0: 224x320 1 face, 155.1ms\n","Speed: 0.0ms preprocess, 155.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\manishi\\_DSC0257_face_1.jpg\n","\n","0: 320x288 1 face, 181.8ms\n","Speed: 3.3ms preprocess, 181.8ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 288)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\manishi\\_DSC0279_face_1.jpg\n","\n","0: 320x224 1 face, 161.9ms\n","Speed: 0.0ms preprocess, 161.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\manishi\\_MG_9957_face_1.jpg\n","\n","0: 320x320 1 face, 190.3ms\n","Speed: 3.0ms preprocess, 190.3ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\nimesh\\IMG_4259_face_1.jpg\n","\n","0: 320x192 1 face, 176.6ms\n","Speed: 2.0ms preprocess, 176.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\nimesh\\IMG_4363_face_1.jpg\n","\n","0: 320x224 1 face, 152.0ms\n","Speed: 1.0ms preprocess, 152.0ms inference, 9.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\nishan\\_DSC0306_face_1.jpg\n","\n","0: 320x224 1 face, 149.0ms\n","Speed: 1.0ms preprocess, 149.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\nishan\\_DSC0307_face_1.jpg\n","\n","0: 320x224 1 face, 147.5ms\n","Speed: 15.9ms preprocess, 147.5ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\nishan\\_DSC0308_face_1.jpg\n","\n","0: 320x224 1 face, 154.0ms\n","Speed: 0.0ms preprocess, 154.0ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\nishan\\_DSC0309_face_1.jpg\n","\n","0: 224x320 1 face, 131.7ms\n","Speed: 15.6ms preprocess, 131.7ms inference, 17.5ms postprocess per image at shape (1, 3, 224, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\omm\\IMG_9877_face_1.jpg\n","\n","0: 224x320 1 face, 132.2ms\n","Speed: 15.6ms preprocess, 132.2ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\omm\\IMG_9883_face_1.jpg\n","\n","0: 320x224 1 face, 147.0ms\n","Speed: 2.0ms preprocess, 147.0ms inference, 9.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\omm\\IMG_9887_face_1.jpg\n","\n","0: 320x192 1 face, 138.3ms\n","Speed: 1.1ms preprocess, 138.3ms inference, 9.0ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\rohan\\IMG_6474_face_1.jpg\n","\n","0: 320x192 1 face, 139.0ms\n","Speed: 2.0ms preprocess, 139.0ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\rohan\\IMG_6475_face_1.jpg\n","\n","0: 320x192 1 face, 135.0ms\n","Speed: 0.8ms preprocess, 135.0ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\rohan\\IMG_6477_face_1.jpg\n","\n","0: 320x192 1 face, 130.8ms\n","Speed: 0.0ms preprocess, 130.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\safal\\IMG_6025_face_1.jpg\n","\n","0: 320x192 1 face, 132.2ms\n","Speed: 0.0ms preprocess, 132.2ms inference, 16.4ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\safal\\IMG_6116_face_1.jpg\n","\n","0: 320x224 1 face, 186.5ms\n","Speed: 0.9ms preprocess, 186.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\safal\\_DSC0314_face_1.jpg\n","\n","0: 320x224 2 faces, 148.8ms\n","Speed: 1.0ms preprocess, 148.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\safal\\_DSC0315_face_1.jpg\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\safal\\_DSC0315_face_2.jpg\n","\n","0: 320x320 1 face, 186.4ms\n","Speed: 3.5ms preprocess, 186.4ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\sagun\\276304952_1115905532596671_5751556272209661412_n_face_1.jpg\n","\n","0: 320x320 4 faces, 189.6ms\n","Speed: 1.0ms preprocess, 189.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\sagun\\278061201_1123308158523075_8198800684869924271_n_face_1.jpg\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\sagun\\278061201_1123308158523075_8198800684869924271_n_face_2.jpg\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\sagun\\278061201_1123308158523075_8198800684869924271_n_face_3.jpg\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\sagun\\278061201_1123308158523075_8198800684869924271_n_face_4.jpg\n","\n","0: 320x320 1 face, 198.0ms\n","Speed: 1.0ms preprocess, 198.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\sagun\\312517340_1265497247637498_3418289357385983168_n_face_1.jpg\n","\n","0: 320x192 1 face, 140.1ms\n","Speed: 2.0ms preprocess, 140.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\sagun\\IMG_6542_face_1.jpg\n","\n","0: 288x320 1 face, 156.2ms\n","Speed: 2.0ms preprocess, 156.2ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\sagun\\_MG_9558_face_1.jpg\n","\n","0: 320x192 1 face, 132.3ms\n","Speed: 0.7ms preprocess, 132.3ms inference, 5.5ms postprocess per image at shape (1, 3, 320, 192)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\shiv\\IMG_6535_face_1.jpg\n","\n","0: 224x320 1 face, 156.4ms\n","Speed: 0.0ms preprocess, 156.4ms inference, 9.9ms postprocess per image at shape (1, 3, 224, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\shiv\\_DSC0151_face_1.jpg\n","\n","0: 320x320 1 face, 197.5ms\n","Speed: 0.0ms preprocess, 197.5ms inference, 4.8ms postprocess per image at shape (1, 3, 320, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\shristi\\_DSC0050_face_1.jpg\n","\n","0: 320x320 1 face, 181.4ms\n","Speed: 0.0ms preprocess, 181.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\shristi\\_DSC0255_face_1.jpg\n","\n","0: 320x224 1 face, 151.3ms\n","Speed: 17.0ms preprocess, 151.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\shristi\\_DSC0279_face_1.jpg\n","\n","0: 320x224 1 face, 166.0ms\n","Speed: 0.0ms preprocess, 166.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\shristi\\_DSC0286_face_1.jpg\n","\n","0: 320x224 1 face, 188.6ms\n","Speed: 0.0ms preprocess, 188.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\SIJAN\\IMG_6070_face_1.jpg\n","\n","0: 224x320 2 faces, 154.0ms\n","Speed: 1.0ms preprocess, 154.0ms inference, 8.0ms postprocess per image at shape (1, 3, 224, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\SIJAN\\_DSC0247_face_1.jpg\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\SIJAN\\_DSC0247_face_2.jpg\n","\n","0: 224x320 3 faces, 159.7ms\n","Speed: 1.8ms preprocess, 159.7ms inference, 4.0ms postprocess per image at shape (1, 3, 224, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\SIJAN\\_DSC0248_face_1.jpg\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\SIJAN\\_DSC0248_face_2.jpg\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\SIJAN\\_DSC0248_face_3.jpg\n","\n","0: 224x320 2 faces, 146.0ms\n","Speed: 1.0ms preprocess, 146.0ms inference, 4.0ms postprocess per image at shape (1, 3, 224, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\SIJAN\\_DSC0261_face_1.jpg\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\SIJAN\\_DSC0261_face_2.jpg\n","\n","0: 224x320 1 face, 147.0ms\n","Speed: 2.0ms preprocess, 147.0ms inference, 4.0ms postprocess per image at shape (1, 3, 224, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\swendeep\\_DSC0062_face_1.jpg\n","\n","0: 288x320 1 face, 160.2ms\n","Speed: 1.0ms preprocess, 160.2ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 320)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\swendeep\\_DSC0298_face_1.jpg\n","\n","0: 320x224 1 face, 157.0ms\n","Speed: 2.0ms preprocess, 157.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\tushar\\IMG_6822_face_1.jpg\n","\n","0: 320x224 1 face, 150.0ms\n","Speed: 1.0ms preprocess, 150.0ms inference, 8.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\yajju\\IMG_6803_face_1.jpg\n","\n","0: 320x224 1 face, 146.2ms\n","Speed: 0.7ms preprocess, 146.2ms inference, 8.0ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\yajju\\_MG_9943_face_1.jpg\n","\n","0: 320x224 1 face, 148.9ms\n","Speed: 0.0ms preprocess, 148.9ms inference, 16.3ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\yajju\\_MG_9944_face_1.jpg\n","\n","0: 320x224 1 face, 156.6ms\n","Speed: 0.0ms preprocess, 156.6ms inference, 8.5ms postprocess per image at shape (1, 3, 320, 224)\n","Saved C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022\\yajju\\_MG_9946_face_1.jpg\n","Face extraction complete.\n"]}],"source":["import os\n","from PIL import Image\n","import cv2\n","from ultralytics import YOLO\n","\n","# Load YOLOv8 model for face detection\n","face_detector = YOLO(r\"C:\\Users\\Jay\\Desktop\\X\\REACO\\yolo\\best.pt\")\n","\n","# Function to extract faces from an image using YOLOv8\n","def extract_faces(image_path, detector):\n","    image = cv2.imread(image_path)\n","    results = detector(image)\n","    faces = []\n","    for result in results:\n","        boxes = result.boxes.xyxy.cpu().numpy()  # Extract bounding boxes\n","        for box in boxes:\n","            x1, y1, x2, y2 = map(int, box[:4])\n","            face = image[y1:y2, x1:x2]\n","            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n","            faces.append(Image.fromarray(face))\n","    return faces\n","\n","# Directory containing images\n","image_folder = r'C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\DATA_2022'\n","output_folder = r'C:\\Users\\Jay\\Desktop\\X\\REACO\\data\\cropped_data_2022'\n","\n","# Process each image in the folder\n","for root, dirs, files in os.walk(image_folder):\n","    for img_name in files:\n","        img_path = os.path.join(root, img_name)\n","        if not os.path.isfile(img_path):\n","            continue\n","\n","        faces = extract_faces(img_path, face_detector)\n","        \n","        # Create the corresponding output directory structure\n","        relative_path = os.path.relpath(root, image_folder)\n","        output_dir = os.path.join(output_folder, relative_path)\n","        os.makedirs(output_dir, exist_ok=True)\n","\n","        # Save the extracted faces\n","        for i, face in enumerate(faces):\n","            face_save_path = os.path.join(output_dir, f\"{os.path.splitext(img_name)[0]}_face_{i + 1}.jpg\")\n","            face.save(face_save_path)\n","            print(f\"Saved {face_save_path}\")\n","\n","print(\"Face extraction complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9VfGwomFLebM"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"envv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":0}
